// src/flows/aiRespond.js

import { think } from "../lib/brain.js";
import { askAnyModel } from "../lib/modelRouter.js";
import { detectFromText } from "../lib/i18n.js";

/** â”€â”€ Ğ¡ĞµÑ€Ğ²Ñ–ÑĞ½Ñ– ÑƒÑ‚Ğ¸Ğ»Ñ–Ñ‚Ğ¸ (Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ– Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
function stripProviderSignature(s = "") {
  return String(s).replace(/^[ \t]*(?:â€”|--)?\s*via\s+[^\n]*\n?/gim, "").trim();
}
function revealsAiSelf(out = "") {
  const s = (out || "").toLowerCase();
  return (
    /(^|\b)as an? (ai|language model)\b/.test(s) ||
    /\bi am (an|a)? (ai|language model|large language model)\b/.test(s) ||
    /\bdeveloped by (google|openai|meta|anthropic)\b/.test(s) ||
    /Ñ\s+(Ñ”|â€”|-)?\s*(ÑˆÑ‚ÑƒÑ‡Ğ½|Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ|Ğ¼Ğ¾Ğ²Ğ°)/i.test(out) ||
    /Ñ\s+(ÑĞ²Ğ»ÑÑÑÑŒ|ĞµÑÑ‚ÑŒ)\s+(Ğ¸Ğ¸|Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½|ÑĞ·Ñ‹ĞºĞ¾Ğ²)/i.test(out) ||
    /ich bin (ein|eine) (ki|sprachmodell)/i.test(out) ||
    /je suis (une|un) (ia|mod[Ã¨e]le de langue)/i.test(out)
  );
}
function looksLikeModelDump(s = "") {
  const x = (s || "").toLowerCase();
  return /here(?:'|)s a breakdown|model (aliases|mappings|configurations)/i.test(x) ||
         /gemini-?2\.5|openrouter|deepseek|llama/i.test(x);
}
function looksLikeEmojiStart(s = "") {
  try { return /^[\u2190-\u2BFF\u2600-\u27BF\u{1F000}-\u{1FAFF}]/u.test(String(s)); }
  catch { return false; }
}
function guessEmoji(text = "") {
  const tt = (text || "").toLowerCase();
  if (tt.includes("ĞºĞ¾Ğ»ĞµÑ") || tt.includes("wheel")) return "ğŸ›";
  if (tt.includes("Ğ´Ğ·ĞµÑ€ĞºĞ°Ğ»") || tt.includes("Ğ·ĞµÑ€ĞºĞ°Ğ»") || tt.includes("mirror")) return "ğŸª";
  if (tt.includes("Ğ¼Ğ°ÑˆĞ¸Ğ½") || tt.includes("Ğ°Ğ²Ñ‚Ğ¾") || tt.includes("car")) return "ğŸš—";
  if (tt.includes("Ğ²Ğ¾Ğ´Ğ°") || tt.includes("Ñ€Ñ–Ğ´Ğ¸Ğ½Ğ°") || tt.includes("water")) return "ğŸ’§";
  if (tt.includes("ÑĞ²Ñ–Ñ‚Ğ»") || tt.includes("light") || tt.includes("ÑĞ¾Ğ»Ğ½Ñ†")) return "â˜€ï¸";
  if (tt.includes("ĞµĞ»ĞµĞºÑ‚Ñ€") || tt.includes("ÑÑ‚Ñ€ÑƒĞ¼") || tt.includes("current")) return "âš¡";
  return "ğŸ’¡";
}
function limitMsg(s, max = 220) {
  if (!s) return s;
  return s.length <= max ? s : s.slice(0, max - 1);
}

/** â”€â”€ ĞÑĞ½Ğ¾Ğ²Ğ½Ğ° Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ñ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export async function aiRespond(env, { text, lang, name, systemHint, expand }) {
  const modelOrder = String(env.MODEL_ORDER || "").trim();

  const control = expand
    ? `You are Senti â€” a thoughtful, emotionally intelligent assistant. Never say you're an AI, model, or a product of any company. Write ONLY in ${lang}; sound natural and human-like. Be warm and helpful. Split long ideas into short Telegram-friendly messages.`
    : `You are Senti â€” an independent, human-like assistant. Never mention being AI/GPT or created by anyone. Write ONLY in ${lang}. Keep it short and helpful (1â€“3 sentences). Answer directly without restating the question.`;

  const prompt = `Add one relevant emoji at the start if natural.
User (${name}) says: ${text}
${control}`;

  // 1) Ğ¿ĞµÑ€ÑˆĞ° ÑĞ¿Ñ€Ğ¾Ğ±Ğ° (model router Ğ°Ğ±Ğ¾ think)
  let out = modelOrder
    ? await askAnyModel(env, modelOrder, prompt, { systemHint })
    : await think(env, prompt, { systemHint });

  out = stripProviderSignature((out || "").trim());

  // 2) ÑĞºÑ‰Ğ¾ Ğ¿Ğ¾Ñ‡Ğ°Ğ² Ğ»Ğ¸Ñ‚Ğ¸ Ñ‚ĞµÑ…Ğ½Ñ–Ñ‡Ğ½Ğ¸Ğ¹ Ğ´Ğ°Ğ¼Ğ¿ Ğ¿Ñ€Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ñ– â€” ÑÑ‚Ñ€Ğ°Ñ…ÑƒÑ”Ğ¼Ğ¾ÑÑ
  if (looksLikeModelDump(out)) {
    const retry = modelOrder
      ? await askAnyModel(env, modelOrder, prompt, { systemHint })
      : await think(env, prompt, { systemHint });
    out = stripProviderSignature((retry || out || "").trim());
  }

  // 3) Ğ°Ğ½Ñ‚Ğ¸-Ñ€Ğ¾Ğ·ĞºÑ€Ğ¸Ñ‚Ñ‚Ñ Â«Ñ AIÂ»
  if (revealsAiSelf(out)) {
    const fix = `Rewrite the previous answer as Senti. Do NOT mention being an AI/model or any company. Keep it in ${lang}, concise and natural.`;
    const cleaned = modelOrder
      ? await askAnyModel(env, modelOrder, fix, { systemHint })
      : await think(env, fix, { systemHint });
    out = stripProviderSignature((cleaned || out || "").trim());
  }

  // 4) Ğ°Ğ²Ñ‚Ğ¾-ĞµĞ¼Ğ¾Ğ´Ğ·Ñ– + Ğ»Ğ°ĞºĞ¾Ğ½Ñ–Ñ‡Ğ½Ñ–ÑÑ‚ÑŒ
  if (!looksLikeEmojiStart(out)) {
    out = `${guessEmoji(text)} ${out}`;
  }

  // 5) ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ¼Ğ¾Ğ²Ğ¸: Ğ¶Ğ¾Ñ€ÑÑ‚ĞºĞ¾ Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑĞ°Ñ‚Ğ¸, ÑĞºÑ‰Ğ¾ Ğ²Ğ¸Ğ¿Ğ°Ğ´ĞºĞ¾Ğ²Ğ¾ Ğ½Ğµ Ñ‚Ñ–Ñ”Ñ Ğ¼Ğ¾Ğ²Ğ¾Ñ
  const detected = detectFromText(out);
  if (detected && lang && detected !== lang) {
    const hardPrompt = `STRICT LANGUAGE MODE: Respond ONLY in ${lang}. If the previous answer used another language, rewrite it now in ${lang}. Keep it concise.`;
    const fixed = modelOrder
      ? await askAnyModel(env, modelOrder, hardPrompt, { systemHint })
      : await think(env, hardPrompt, { systemHint });
    const clean = stripProviderSignature((fixed || "").trim());
    out = looksLikeEmojiStart(clean) ? clean : `${guessEmoji(text)} ${clean}`;
  }

  const short = expand ? out : limitMsg(out, 220);
  return { short, full: out };
}