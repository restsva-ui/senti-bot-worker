// src/flows/visionDescribe.js
// –Ñ–¥–∏–Ω–∞ —Ç–æ—á–∫–∞ –¥–ª—è –æ–ø–∏—Å—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –º—É–ª—å—Ç–∏–º–æ–≤–Ω—ñ—Å—Ç—é.
//
// –ü—Ä–∞–≤–∫–∏:
// 1) –∫–∞—Å–∫–∞–¥ –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: gemini:gemini-2.5-flash –ø–µ—Ä—à–∏–º;
// 2) —è–∫—â–æ —é–∑–µ—Ä –ù–ï –ø–∏—Ç–∞–≤ –ø—Ä–æ —Ç–µ–∫—Å—Ç ‚Äî –Ω–µ –ø–æ–∫–∞–∑—É—î–º–æ "—Ç–µ–∫—Å—Ç –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ";
// 3) –ø—Ä–∏–±—Ä–∞–Ω–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏ —Ä—è–¥–∫—ñ–≤;
// 4) –º–æ–≤–∞ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è/—á–∏—Ç–∞—î—Ç—å—Å—è –∑ KV —á–µ—Ä–µ–∑ src/lib/langPref.js

import { askVision } from "../lib/modelRouter.js";
import {
  buildVisionHintByLang,
  makeVisionUserPrompt,
  postprocessVisionText,
} from "./visionPolicy.js";
import { getUserLang, setUserLang } from "../lib/langPref.js";

// —á–∏ —é–∑–µ—Ä —è–≤–Ω–æ –ø—Ä–æ—Å–∏–≤ –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ —Ç–µ–∫—Å—Ç/–Ω–∞–¥–ø–∏—Å
function userAskedForText(q = "") {
  const s = q.toLowerCase();
  return (
    s.includes("—Ç–µ–∫—Å—Ç") ||
    s.includes("—â–æ –Ω–∞–ø–∏—Å–∞–Ω–æ") ||
    s.includes("–Ω–∞–¥–ø–∏—Å") ||
    s.includes("–Ω–∞–ø–∏—Å–∏") ||
    s.includes("text on") ||
    s.includes("what is written") ||
    s.includes("read the text")
  );
}

// –ø—Ä–∏–±–∏—Ä–∞—î–º–æ OCR-–±–ª–æ–∫–∏, —è–∫—â–æ –≤–æ–Ω–∏ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ
function stripOcrBlocks(text) {
  const lines = String(text || "").split("\n");
  const out = [];
  for (const ln of lines) {
    const low = ln.trim().toLowerCase();
    if (
      low.startsWith("üìù") ||
      low.startsWith("—Ç–µ–∫—Å—Ç –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ") ||
      low.startsWith("text on the image") ||
      low.startsWith("text on image")
    ) {
      continue;
    }
    out.push(ln);
  }
  // –ø—Ä–∏–±–∏—Ä–∞—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏
  const uniq = [];
  const seen = new Set();
  for (const ln of out) {
    const key = ln.trim();
    if (!key) continue;
    if (seen.has(key)) continue;
    seen.add(key);
    uniq.push(ln);
  }
  return uniq.join("\n").trim();
}

/**
 * @param {object} env
 * @param {object} p
 * @param {string|number} p.chatId
 * @param {string} [p.tgLang]
 * @param {string} p.imageBase64
 * @param {string} [p.question]
 * @param {string} [p.modelOrder] - –º–æ–∂–Ω–∞ —è–≤–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç–∏ —Å–≤—ñ–π –ø–æ—Ä—è–¥–æ–∫
 */
export async function describeImage(
  env,
  { chatId, tgLang, imageBase64, question, modelOrder }
) {
  // 1) –≤–∏–∑–Ω–∞—á–∞—î–º–æ –º–æ–≤—É: KV ‚Üí tgLang ‚Üí "uk"
  const lang = await getUserLang(env, chatId, tgLang);
  // —è–∫—â–æ —Ç–µ–ª–µ–≥—Ä–∞–º –¥–∞–≤ –Ω–æ–≤—É –º–æ–≤—É ‚Äî –æ–Ω–æ–≤–∏–º–æ KV
  if (tgLang && tgLang.toLowerCase() !== lang) {
    await setUserLang(env, chatId, tgLang);
  }

  // 2) system + user
  const systemHint = buildVisionHintByLang(lang);
  const userPrompt = makeVisionUserPrompt(question, lang);

  // 3) –∫–∞—Å–∫–∞–¥: —Ç–µ–ø–µ—Ä –ø–µ—Ä—à–∞ ‚Äî gemini 2.5 flash
  const order =
    modelOrder ||
    "gemini:gemini-2.5-flash, cf:@cf/meta/llama-3.2-11b-vision-instruct";

  // 4) –≤–∏–∫–ª–∏–∫ –º–æ–¥–µ–ª—ñ
  const out = await askVision(env, order, userPrompt, {
    systemHint,
    imageBase64,
    imageMime: "image/png",
    temperature: 0.2,
  });

  // 5) –ø–æ—Å—Ç–ø—Ä–æ—Ü
  let text = postprocessVisionText(out);

  // —è–∫—â–æ —é–∑–µ—Ä –Ω–µ –ø–∏—Ç–∞–≤ –ø—Ä–æ —Ç–µ–∫—Å—Ç ‚Äî –ø—Ä–∏–±–∏—Ä–∞—î–º–æ OCR-–±–ª–æ–∫–∏
  if (!userAskedForText(question || "")) {
    text = stripOcrBlocks(text);
  }

  return { text };
}
 
