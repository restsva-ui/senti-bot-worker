// src/routes/webhook.js
// (rev) –ë–µ–∑ –≤—ñ—Ç–∞–ª—å–Ω–æ–≥–æ –≤—ñ–¥–µ–æ; —Ç–∏—Ö–µ –ø–µ—Ä–µ–º–∏–∫–∞–Ω–Ω—è —Ä–µ–∂–∏–º—ñ–≤; —Ñ—ñ–∫—Å –º–æ–≤–∏ –Ω–∞ /start;
// –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è Google Drive; –¥—Ä—É–∂–Ω—ñ–π —Ñ–æ–ª–±–µ–∫ –¥–ª—è –º–µ–¥—ñ–∞ –≤ Senti;
// –∞–≤—Ç–æ-—Å–∞–º–æ—Ç—é–Ω—ñ–Ω–≥ —Å—Ç–∏–ª—é (–º–æ–≤–Ω—ñ –ø—Ä–æ—Ñ—ñ–ª—ñ) —á–µ—Ä–µ–∑ selfTune.
// (upd) Vision —á–µ—Ä–µ–∑ –∫–∞—Å–∫–∞–¥ –º–æ–¥–µ–ª–µ–π (–º—É–ª—å—Ç–∏–º–æ–≤–Ω–∏–π) + base64 —ñ–∑ Telegram —Ñ–∞–π–ª—ñ–≤.
// (new) Vision Memory —É KV: –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ 20 —Ñ–æ—Ç–æ –∑ –æ–ø–∏—Å–∞–º–∏.

import { driveSaveFromUrl } from "../lib/drive.js";
import { getUserTokens } from "../lib/userDrive.js";
import { abs } from "../utils/url.js";
import { think } from "../lib/brain.js";
import { readStatut } from "../lib/kvChecklist.js";
import { askAnyModel, getAiHealthSummary } from "../lib/modelRouter.js";
import { json } from "../lib/utils.js";
import { getEnergy, spendEnergy } from "../lib/energy.js";
import { buildDialogHint, pushTurn } from "../lib/dialogMemory.js";
import { buildSystemHint } from "../lib/systemHint.js";
import { getPreferredName } from "../lib/profile.js";
import { pickReplyLanguage, t } from "../lib/i18n.js";
import { chunkText, limitMsg } from "../utils/text.js";
import { sendPlain, tgFileUrl, sendTyping } from "../lib/telegram.js";
import { getDriveMode } from "../lib/driveMode.js";
import { describeImage } from "../flows/visionDescribe.js";
import weatherApi from "../apis/weather.js";
import { detectLandmarksFromText, formatLandmarkLines } from "../lib/landmarkDetect.js";

const {
  BTN_DRIVE, BTN_SENTI, BTN_ADMIN, BTN_LEARN,
  mainKeyboard, adminKeyboard,
} = await import("../lib/tg.js");

const ADMIN = (env, userId) => {
  const ids = String(env.ADMIN_IDS || "").split(/[,\s]+/).filter(Boolean);
  return ids.includes(String(userId));
};

// ===== vision memory =====
const VISION_MEM_KEY = (uid) => `vision:mem:${uid}`;
async function loadVisionMem(env, userId) {
  try {
    const raw = await (env.STATE_KV || env.CHECKLIST_KV)?.get(VISION_MEM_KEY(userId), "text");
    return raw ? JSON.parse(raw) : [];
  } catch { return []; }
}
async function saveVisionMem(env, userId, entry) {
  const kv = env.STATE_KV || env.CHECKLIST_KV;
  if (!kv) return;
  try {
    const arr = await loadVisionMem(env, userId);
    arr.unshift({
      id: entry.id,
      url: entry.url,
      caption: entry.caption || "",
      desc: entry.desc || "",
      ts: Date.now()
    });
    const trimmed = arr.slice(0, 20);
    await kv.put(VISION_MEM_KEY(userId), JSON.stringify(trimmed), {
      expirationTtl: 60 * 60 * 24 * 180
    });
  } catch {}
}
// –ø—Ä–æ—Å—Ç–∏–π ‚Äútyping‚Äù
async function sendTypingSafe(env, chatId) {
  try {
    await sendTyping(env, chatId);
  } catch {}
}
function pulseTyping(env, chatId, times = 4, intervalMs = 4000) {
  sendTypingSafe(env, chatId);
  for (let i = 1; i < times; i++) setTimeout(() => sendTypingSafe(env, chatId), i * intervalMs);
}

// base64 –∑ tg
async function urlToBase64(url) {
  const r = await fetch(url);
  if (!r.ok) throw new Error(`fetch image ${r.status}`);
  const ab = await r.arrayBuffer();
  const bytes = new Uint8Array(ab);
  let bin = "";
  for (let i = 0; i < bytes.length; i++) bin += String.fromCharCode(bytes[i]);
  return btoa(bin);
}

// media helpers
function pickPhoto(msg) {
  const arr = Array.isArray(msg?.photo) ? msg.photo : null;
  if (!arr?.length) return null;
  const ph = arr[arr.length - 1];
  return { type: "photo", file_id: ph.file_id, name: `photo_${ph.file_unique_id}.jpg` };
}
function detectAttachment(msg) {
  if (!msg) return null;
  if (msg.document) return { type: "document", file_id: msg.document.file_id, name: msg.document.file_name };
  if (msg.video) return { type: "video", file_id: msg.video.file_id, name: msg.video.file_name || "video.mp4" };
  if (msg.audio) return { type: "audio", file_id: msg.audio.file_id, name: msg.audio.file_name || "audio.mp3" };
  if (msg.voice) return { type: "voice", file_id: msg.voice.file_id, name: "voice.ogg" };
  if (msg.video_note) return { type: "video_note", file_id: msg.video_note.file_id, name: "video_note.mp4" };
  return null;
}

// clean vision text –≤—ñ–¥ –ø–æ–≤—Ç–æ—Ä—ñ–≤
function cleanVisionText(text = "", lang = "uk") {
  let t = String(text || "").trim();
  t = t.replace(/\r/g, "").replace(/[ \t]+\n/g, "\n").replace(/\n{3,}/g, "\n\n");
  // –ø—Ä–∏–±—Ä–∞—Ç–∏ ‚Äú–Ω–µ–º–∞—î —Ç–µ–∫—Å—Ç—É‚Äù —è–∫ –æ–∫—Ä–µ–º–∏–π —Ä—è–¥–æ–∫
  t = t.replace(/–¢–µ–∫—Å—Ç –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ:\s*("?"?(–Ω–µ–º–∞—î|–Ω–µ–º–∞|no text|none)"?"?)?/gi, "").trim();
  // —É–∫–æ—Ä–æ—á–µ–Ω–Ω—è
  const parts = t.split("\n").filter(Boolean);
  if (parts.length > 4) t = parts.slice(0, 4).join("\n");
  return t;
}

// –¥–ª—è –µ–Ω–µ—Ä–≥—ñ—ó (—è–∫ —É —Ç–µ–±–µ –±—É–ª–æ)
function energyLinks(env, userId) {
  const base = abs(env, `/admin/energy?uid=${encodeURIComponent(userId)}`);
  return { energy: base };
}
// VISION handler
async function handleVisionMedia(env, chatId, userId, msg, lang, caption) {
  const att = pickPhoto(msg);
  if (!att) return false;

  const cur = await getEnergy(env, userId);
  const need = Number(cur.costText ?? 1);
  if ((cur.energy ?? 0) < need) {
    const links = energyLinks(env, userId);
    await sendPlain(env, chatId, t(
      lang, "need_energy_text", need, links.energy));
    return true;
  }
  await spendEnergy(env, userId, need, "vision");

  pulseTyping(env, chatId);

  const url = await tgFileUrl(env, att.file_id);
  const imageBase64 = await urlToBase64(url);
  const prompt = caption || (lang.startsWith("uk")
    ? "–û–ø–∏—à–∏, —â–æ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ, –±–µ–∑ –ø–æ–≤—Ç–æ—Ä—ñ–≤ —ñ –±–µ–∑ —Ñ–∞–Ω—Ç–∞–∑—ñ–π."
    : "Describe what is in the image, without repetitions and without fantasy.");

  try {
    const visionRes = await describeImage(env, {
      imageBase64,
      question: prompt,
      lang,
      userId: userId?.toString?.() || "anon",
      // –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–Ω–æ ENV –¥–ª—è vision
      modelOrder: (env.MODEL_ORDER_VISION || env.VISION_ORDER || env.MODEL_ORDER || "gemini:gemini-2.5-flash, cf:@cf/meta/llama-3.2-11b-vision-instruct"),
    });

    if (!visionRes?.text) throw new Error("vision failed");
    let text = cleanVisionText(visionRes.text, lang);
    const landmarks = detectLandmarksFromText(text, lang);

    await saveVisionMem(env, userId, { id: att.file_id, url, caption, desc: text });

    await sendPlain(env, chatId, `üñºÔ∏è ${text}`, {
      parse_mode: landmarks.length ? "HTML" : undefined,
      reply_markup: landmarks.length ? {
        inline_keyboard: [formatLandmarkLines(landmarks)]
      } : undefined
    });
  } catch (err) {
    await sendPlain(env, chatId, lang.startsWith("uk")
      ? "‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ñ–æ—Ç–æ."
      : "‚ùå Failed to analyze the image.");
  }
  return true;
}
export async function handleTelegramWebhook(req, env) {
  if (req.method === "POST") {
    const sec = req.headers.get("x-telegram-bot-api-secret-token");
    const expected = env.TG_WEBHOOK_SECRET || env.TELEGRAM_SECRET_TOKEN || env.WEBHOOK_SECRET || "";
    if (expected && sec !== expected) {
      return json({ ok: false, error: "unauthorized" }, { status: 401 });
    }
  } else {
    return json({ ok: true, note: "webhook alive (GET)" });
  }

  let update;
  try { update = await req.json(); } catch { return json({ ok: false }, { status: 400 }); }

  // callback_query —Ç—É—Ç —è–∫ —É —Ç–µ–±–µ –±—É–ª–æ ‚Ä¶
  if (update.callback_query) {
    // ... –∑–∞–ª–∏—à–∞—î–º–æ —Ç–≤—ñ–π –æ–±—Ä–æ–±–Ω–∏–∫ –∫–Ω–æ–ø–æ–∫ admin/learn
  }

  const msg = update.message || update.edited_message || update.channel_post;
  const chatId = msg?.chat?.id;
  const userId = msg?.from?.id;
  const isAdmin = ADMIN(env, userId);
  const textRaw = String(msg?.text || msg?.caption || "").trim();
  let lang = pickReplyLanguage(msg, textRaw);

  // –ª–æ–∫–∞—Ü—ñ—è ‚Üí –∑–±–µ—Ä–µ–≥–ª–∏
  if (msg?.location && userId && chatId) {
    await setUserLocation(env, userId, msg.location);
    await sendPlain(env, chatId, "‚úÖ –õ–æ–∫–∞—Ü—ñ—é –∑–±–µ—Ä–µ–∂–µ–Ω–æ. –¢–µ–ø–µ—Ä –º–æ–∂–Ω–∞ –ø–∏—Ç–∞—Ç–∏ –ø–æ–≥–æ–¥—É.");
    return json({ ok: true });
  }

  // ‚õÖÔ∏è –î–û–ë–ê–í–õ–ï–ù–û: –ø–æ–≥–æ–¥–∞ –ø–æ —Ç–µ–∫—Å—Ç—É
  if (textRaw && (/^–ø–æ–≥–æ–¥–∞\b/i.test(textRaw) || /^weather\b/i.test(textRaw) ||
    textRaw.toLowerCase().startsWith("–ø–æ–≥–æ–¥–∞ ") || textRaw.toLowerCase().startsWith("weather "))) {
    const place = textRaw.split(/\s+/).slice(1).join(" ").trim();
    const w = place
      ? await weatherApi.weatherSummaryByPlace(place, lang)
      : { text: "–°–∫–∞–∂–∏, –¥–ª—è —è–∫–æ–≥–æ –º—ñ—Å—Ç–∞ –ø–æ–∫–∞–∑–∞—Ç–∏ –ø–æ–≥–æ–¥—É üëá" };
    await sendPlain(env, chatId, w.text || "–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –ø–æ–≥–æ–¥—É.");
    return json({ ok: true });
  }

  // MEDIA routing
  try {
    const driveOn = await getDriveMode(env, userId);
    const hasAnyMedia = !!detectAttachment(msg) || !!pickPhoto(msg);

    if (driveOn && hasAnyMedia) {
      const handled = await handleIncomingMedia(env, chatId, userId, msg, lang);
      // üëá –î–û–ë–ê–í–õ–ï–ù–û: —è–∫—â–æ —Ü–µ –±—É–ª–æ —Ñ–æ—Ç–æ –±–µ–∑ –ø—ñ–¥–ø–∏—Å—É ‚Äî —Å–ø–∏—Ç–∞–π, —â–æ –∑—Ä–æ–±–∏—Ç–∏
      if (handled && pickPhoto(msg) && !msg.caption) {
        await sendPlain(
          env,
          chatId,
          lang.startsWith("uk")
            ? "–§–æ—Ç–æ –∑–±–µ—Ä—ñ–≥ ‚úÖ –©–æ –∑ –Ω–∏–º –∑—Ä–æ–±–∏—Ç–∏? (–æ–ø–∏—Å–∞—Ç–∏ / –∑–º—ñ–Ω–∏—Ç–∏ / –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏)"
            : "Saved the photo ‚úÖ What should I do with it? (describe / edit / forward)"
        );
      }
      if (handled) return json({ ok: true });
    }

    if (!driveOn && pickPhoto(msg)) {
      if (await handleVisionMedia(env, chatId, userId, msg, lang, msg.caption)) return json({ ok: true });
    }

    // ‚Ä¶ –¥–∞–ª—ñ –ª–∏—à–∞—î—à —Ç–≤—ñ–π —ñ—Å–Ω—É—é—á–∏–π –æ–±—Ä–æ–±–Ω–∏–∫ —Ç–µ–∫—Å—Ç—É /admin /learn /start
  } catch (err) {
    if (isAdmin) await sendPlain(env, chatId, `‚ùå ${String(err?.message || err)}`);
  }

  // –¥–µ—Ñ–æ–ª—Ç —è–∫ —É —Ç–µ–±–µ –±—É–ª–æ‚Ä¶
  await sendPlain(env, chatId, "üëã –Ø —Ç—É—Ç. –©–æ —Ä–æ–±–∏–º–æ –¥–∞–ª—ñ?", {
    reply_markup: mainKeyboard(isAdmin)
  });
  return json({ ok: true });
}
