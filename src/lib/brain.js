// src/lib/brain.js
// "ÐœÐ¾Ð·Ð¾Ðº" Senti:
// 1) Ð¯ÐºÑ‰Ð¾ Ð·Ð°Ð´Ð°Ð½Ð¾ MODEL_ORDER â€” Ð¹Ð´ÐµÐ¼Ð¾ Ñ‡ÐµÑ€ÐµÐ· Ñ€Ð¾ÑƒÑ‚ÐµÑ€ (Gemini / CF / OpenRouter Ð² Ð±ÑƒÐ´ÑŒ-ÑÐºÐ¾Ð¼Ñƒ Ð¿Ð¾Ñ€ÑÐ´ÐºÑƒ).
// 2) Ð¯ÐºÑ‰Ð¾ MODEL_ORDER Ð½ÐµÐ¼Ð°Ñ” â€” Ð¿Ñ€Ð¾Ð±ÑƒÑ”Ð¼Ð¾ Gemini (GEMINI_API_KEY Ð°Ð±Ð¾ GOOGLE_API_KEY),
//    Ð¿Ð¾Ñ‚Ñ–Ð¼ OpenRouter, Ð´Ð°Ð»Ñ– Ð¼â€™ÑÐºÐ¸Ð¹ Ñ„Ð¾Ð»Ð±ÐµÐº.
// 3) aiDiag(env) â€” Ð°ÐºÑ‚Ð¸Ð²Ð½Ð° Ð´Ñ–Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ñ–Ð².

import { askAnyModel } from "../lib/modelRouter.js";

const GEMINI_BASE = "https://generativelanguage.googleapis.com/v1beta/models";

/* â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
async function tryGeminiDirect(env, text, systemHint, opts = {}) {
  const key = env.GEMINI_API_KEY || env.GOOGLE_API_KEY;
  if (!key) return { ok: false, out: null, err: "no_key" };

  const modelId = "gemini-1.5-flash-latest";
  const url = `${GEMINI_BASE}/${encodeURIComponent(modelId)}:generateContent?key=${key}`;

  const body = {
    contents: [
      {
        role: "user",
        parts: [{ text: systemHint ? `${systemHint}\n\n${text}` : text }],
      },
    ],
    generationConfig: {
      temperature: opts.temperature ?? 0.6,
      maxOutputTokens: opts.max_tokens ?? 1024,
    },
  };

  try {
    const r = await fetch(url, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(body),
    });
    const j = await r.json().catch(() => ({}));
    if (!r.ok) return { ok: false, out: null, err: `HTTP ${r.status}: ${j?.error?.message || j?.error?.status || "gemini_error"}` };
    const out = j?.candidates?.[0]?.content?.parts?.[0]?.text || null;
    return { ok: !!out, out, err: out ? null : "empty" };
  } catch (e) {
    return { ok: false, out: null, err: String(e) };
  }
}

async function tryOpenRouterDirect(env, text, systemHint, opts = {}) {
  if (!env.OPENROUTER_API_KEY) return { ok: false, out: null, err: "no_key" };

  try {
    const r = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${env.OPENROUTER_API_KEY}`,
      },
      body: JSON.stringify({
        model: env.OPENROUTER_MODEL || "deepseek/deepseek-chat",
        messages: [
          ...(systemHint ? [{ role: "system", content: systemHint }] : []),
          { role: "user", content: text },
        ],
        temperature: opts.temperature ?? 0.6,
        max_tokens: opts.max_tokens ?? 1024,
      }),
    });
    const j = await r.json().catch(() => ({}));
    if (!r.ok) return { ok: false, out: null, err: `HTTP ${r.status}: ${j?.error?.message || j?.error || "openrouter_error"}` };
    const out = j?.choices?.[0]?.message?.content || null;
    return { ok: !!out, out, err: out ? null : "empty" };
  } catch (e) {
    return { ok: false, out: null, err: String(e) };
  }
}

/* â”€â”€ public: Ð¾ÑÐ½Ð¾Ð²Ð½Ð° Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export async function think(env, userText, systemHint = "") {
  const text = String(userText || "").trim();
  if (!text) return "ðŸ¤– Ð”Ð°Ð¹ Ð¼ÐµÐ½Ñ– Ñ‚ÐµÐºÑÑ‚ Ð°Ð±Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ â€” Ñ– Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð¼.";

  // 0) Ð¯ÐºÑ‰Ð¾ Ð·Ð°Ð´Ð°Ð½Ð¸Ð¹ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ñ–Ð² â€” Ð¿Ñ€Ð¾Ð±ÑƒÑ”Ð¼Ð¾ Ñ‡ÐµÑ€ÐµÐ· Ñ€Ð¾ÑƒÑ‚ÐµÑ€
  if (env.MODEL_ORDER) {
    try {
      const merged = systemHint ? `${systemHint}\n\nÐšÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡: ${text}` : text;
      return await askAnyModel(env, merged, { temperature: 0.6, max_tokens: 1024 });
    } catch (e) {
      // Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ð¼Ð¾ Ñ€ÐµÐ·ÐµÑ€Ð²Ð°Ð¼Ð¸
      console.log("Router failed:", e?.message || e);
    }
  }

  // 1) Gemini Ð½Ð°Ð¿Ñ€ÑÐ¼Ñƒ
  const g = await tryGeminiDirect(env, text, systemHint, { temperature: 0.6, max_tokens: 1024 });
  if (g.ok && g.out) return g.out;

  // 2) OpenRouter Ð½Ð°Ð¿Ñ€ÑÐ¼Ñƒ
  const o = await tryOpenRouterDirect(env, text, systemHint, { temperature: 0.6, max_tokens: 1024 });
  if (o.ok && o.out) return o.out;

  // 3) Ðœâ€™ÑÐºÐ¸Ð¹ Ñ„Ð¾Ð»Ð±ÐµÐº Ð· Ð¿Ñ–Ð´ÐºÐ°Ð·ÐºÐ°Ð¼Ð¸, Ñ‡Ð¾Ð¼Ñƒ Ð½Ðµ ÑÐ¿Ñ€Ð°Ñ†ÑŽÐ²Ð°Ð»Ð¾
  const tips = [];
  if (!env.GEMINI_API_KEY && !env.GOOGLE_API_KEY) tips.push("â€¢ Ð”Ð¾Ð´Ð°Ð¹ GEMINI_API_KEY Ð°Ð±Ð¾ GOOGLE_API_KEY (AI Studio)");
  if (!env.OPENROUTER_API_KEY) tips.push("â€¢ ÐÐ±Ð¾ OPENROUTER_API_KEY (+ OPENROUTER_MODEL, Ð·Ð° Ð±Ð°Ð¶Ð°Ð½Ð½Ñ)");
  if (!env.CF_ACCOUNT_ID || !env.CLOUDFLARE_API_TOKEN) tips.push("â€¢ ÐÐ±Ð¾ ÑƒÐ²Ñ–Ð¼ÐºÐ½Ð¸ Cloudflare Workers AI (CF_ACCOUNT_ID + CLOUDFLARE_API_TOKEN) Ñ– Ð·Ð°Ð´Ð°Ð¹ MODEL_ORDER");

  return (
    "ðŸ§  ÐŸÐ¾ÐºÐ¸ Ñ‰Ð¾ Ñ Ð¿Ñ€Ð°Ñ†ÑŽÑŽ Ñƒ Ð»ÐµÐ³ÐºÐ¾Ð¼Ñƒ Ñ€ÐµÐ¶Ð¸Ð¼Ñ– Ð±ÐµÐ· Ð·Ð¾Ð²Ð½Ñ–ÑˆÐ½Ñ–Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹.\n" +
    (tips.length ? "Ð¯Ðº ÑƒÐ²Ñ–Ð¼ÐºÐ½ÑƒÑ‚Ð¸ Ð±ÐµÐ·ÐºÐ¾ÑˆÑ‚Ð¾Ð²Ð½Ð¾:\n" + tips.join("\n") + "\n" : "") +
    "ÐœÐ¾Ð¶ÐµÑˆ Ð·Ð°Ð´Ð°Ñ‚Ð¸ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº Ñƒ MODEL_ORDER (Ð½Ð°Ð¿Ñ€.: gemini:gemini-1.5-flash-latest,cf:@cf/meta/llama-3-8b-instruct,openrouter:deepseek/deepseek-chat)."
  );
}

/* â”€â”€ public: Ð´Ñ–Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
export async function aiDiag(env) {
  const present = {
    GEMINI_API_KEY: !!env.GEMINI_API_KEY,
    GOOGLE_API_KEY: !!env.GOOGLE_API_KEY,
    CF_ACCOUNT_ID: !!env.CF_ACCOUNT_ID,
    CLOUDFLARE_API_TOKEN: !!env.CLOUDFLARE_API_TOKEN,
    OPENROUTER_API_KEY: !!env.OPENROUTER_API_KEY,
    OPENROUTER_MODEL: env.OPENROUTER_MODEL || "",
    MODEL_ORDER: env.MODEL_ORDER || "",
  };

  const results = {};

  // Gemini quick check
  if (present.GEMINI_API_KEY || present.GOOGLE_API_KEY) {
    const ping = await tryGeminiDirect(env, "ping", "", { temperature: 0.1, max_tokens: 16 });
    results.gemini = ping.ok
      ? { ok: true, sample: (ping.out || "").slice(0, 80) }
      : { ok: false, err: ping.err };
  } else {
    results.gemini = { ok: false, err: "no_key" };
  }

  // Cloudflare quick check (Ð±ÐµÐ·Ð¿ÐµÑ‡Ð½Ð¾: ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ prompt)
  if (present.CF_ACCOUNT_ID && present.CLOUDFLARE_API_TOKEN) {
    try {
      const url = `https://api.cloudflare.com/client/v4/accounts/${env.CF_ACCOUNT_ID}/ai/run/${encodeURIComponent("@cf/meta/llama-3-8b-instruct")}`;
      const r = await fetch(url, {
        method: "POST",
        headers: {
          Authorization: `Bearer ${env.CLOUDFLARE_API_TOKEN}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ messages: [{ role: "user", content: "ping" }] }),
      });
      const j = await r.json().catch(() => ({}));
      results.cloudflare = r.ok && j?.success !== false
        ? { ok: true, sample: (j?.result?.response || j?.result?.output_text || "").slice(0, 80) }
        : { ok: false, err: j?.errors?.[0]?.message || "no_route_or_denied" };
    } catch (e) {
      results.cloudflare = { ok: false, err: String(e) };
    }
  } else {
    results.cloudflare = { ok: false, err: "no_creds" };
  }

  // OpenRouter quick check
  if (present.OPENROUTER_API_KEY) {
    try {
      const r = await fetch("https://openrouter.ai/api/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${env.OPENROUTER_API_KEY}`,
        },
        body: JSON.stringify({
          model: present.OPENROUTER_MODEL || "deepseek/deepseek-chat",
          messages: [{ role: "user", content: "ping" }],
          max_tokens: 16,
        }),
      });
      const j = await r.json().catch(() => ({}));
      results.openrouter = r.ok
        ? { ok: true, sample: (j?.choices?.[0]?.message?.content || "").slice(0, 80) }
        : { ok: false, err: j?.error?.message || "denied_or_no_funds" };
    } catch (e) {
      results.openrouter = { ok: false, err: String(e) };
    }
  } else {
    results.openrouter = { ok: false, err: "no_key" };
  }

  return { present, results };
}